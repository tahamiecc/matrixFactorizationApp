{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matris FaktÃ¶rizasyon AlgoritmalarÄ± - DetaylÄ± Analiz\n",
        "\n",
        "Bu notebook, matris faktÃ¶rizasyon algoritmalarÄ±nÄ±n detaylÄ± analizini ve gÃ¶rselleÅŸtirmelerini iÃ§erir.\n",
        "\n",
        "## Ä°Ã§indekiler\n",
        "1. SVD - Ã–neri Sistemi\n",
        "2. SVD - GÃ¼rÃ¼ltÃ¼ Temizleme\n",
        "3. PCA - Veri GÃ¶rselleÅŸtirme\n",
        "4. NMF - GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme\n",
        "5. NMF - Topic Modeling\n",
        "6. ALS - Ã–neri Sistemi\n",
        "7. Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri import et\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Algoritmalar\n",
        "from algorithms.svd import SVDRecommender, SVDNoiseReducer\n",
        "from algorithms.pca import PCAAnalyzer\n",
        "from algorithms.nmf import NMFImageProcessor, NMFTopicModeler\n",
        "from algorithms.als import ALSRecommender\n",
        "\n",
        "# YardÄ±mcÄ± fonksiyonlar\n",
        "from utils.data_loader import (\n",
        "    generate_sample_data, \n",
        "    generate_rating_matrix,\n",
        "    load_sample_images,\n",
        "    generate_text_corpus,\n",
        "    generate_noisy_data\n",
        ")\n",
        "from utils.visualization import (\n",
        "    plot_ratings_matrix,\n",
        "    plot_recommendations,\n",
        "    plot_image_grid,\n",
        "    plot_topic_words\n",
        ")\n",
        "\n",
        "# GÃ¶rselleÅŸtirme ayarlarÄ±\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"âœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. SVD - Ã–neri Sistemi\n",
        "\n",
        "### ğŸ“š SVD (Singular Value Decomposition) Nedir?\n",
        "\n",
        "**SVD**, bir matrisi Ã¼Ã§ matrisin Ã§arpÄ±mÄ±na ayÄ±ran matematiksel bir yÃ¶ntemdir:\n",
        "- **U**: Sol tekil vektÃ¶rler matrisi (kullanÄ±cÄ± Ã¶zellikleri)\n",
        "- **Î£**: Tekil deÄŸerler matrisi (kÃ¶ÅŸegen matris, bileÅŸen Ã¶nemleri)\n",
        "- **V^T**: SaÄŸ tekil vektÃ¶rler matrisi (Ã¼rÃ¼n Ã¶zellikleri)\n",
        "\n",
        "### ğŸ¯ Ã–neri Sistemlerinde KullanÄ±mÄ±\n",
        "\n",
        "1. **Rating Matrisi FaktÃ¶rizasyonu**: KullanÄ±cÄ±-Ã¼rÃ¼n rating matrisini dÃ¼ÅŸÃ¼k rank matrislere ayÄ±rÄ±r\n",
        "2. **Latent FaktÃ¶rler**: Gizli kullanÄ±cÄ± ve Ã¼rÃ¼n Ã¶zelliklerini keÅŸfeder\n",
        "3. **Eksik Rating Tahmini**: KullanÄ±cÄ±larÄ±n henÃ¼z deÄŸerlendirmediÄŸi Ã¼rÃ¼nler iÃ§in rating tahmin eder\n",
        "\n",
        "### ğŸ“Š Metrikler\n",
        "\n",
        "- **RMSE (Root Mean Square Error)**: Tahmin hatasÄ±nÄ±n Ã¶lÃ§Ã¼sÃ¼. DÃ¼ÅŸÃ¼k deÄŸer = daha iyi performans\n",
        "- **Tekil DeÄŸerler**: Her bileÅŸenin Ã¶nemini gÃ¶sterir. BÃ¼yÃ¼k deÄŸerler = daha Ã¶nemli bileÅŸenler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–rnek rating matrisi oluÅŸtur\n",
        "print(\"Rating matrisi oluÅŸturuluyor...\")\n",
        "rating_matrix = generate_rating_matrix(n_users=100, n_items=50, sparsity=0.7)\n",
        "print(f\"Rating matrisi boyutu: {rating_matrix.shape}\")\n",
        "print(f\"Dolu rating sayÄ±sÄ±: {np.sum(~np.isnan(rating_matrix))}\")\n",
        "\n",
        "# Train-test split\n",
        "np.random.seed(42)\n",
        "mask = ~np.isnan(rating_matrix)\n",
        "test_indices = np.random.choice(np.where(mask)[0], \n",
        "                               size=int(0.2 * np.sum(mask)), \n",
        "                               replace=False)\n",
        "test_mask = np.zeros_like(mask, dtype=bool)\n",
        "test_mask.flat[test_indices] = True\n",
        "\n",
        "train_matrix = rating_matrix.copy()\n",
        "train_matrix[test_mask] = np.nan\n",
        "\n",
        "test_matrix = np.full_like(rating_matrix, np.nan)\n",
        "test_matrix[test_mask] = rating_matrix[test_mask]\n",
        "\n",
        "# SVD modeli eÄŸit\n",
        "print(\"\\nSVD modeli eÄŸitiliyor...\")\n",
        "svd_model = SVDRecommender(n_components=20)\n",
        "svd_model.fit(train_matrix)\n",
        "\n",
        "# DeÄŸerlendirme\n",
        "rmse = svd_model.evaluate(test_matrix)\n",
        "singular_values = svd_model.get_singular_values()\n",
        "\n",
        "print(f\"\\nTest RMSE: {rmse:.4f}\")\n",
        "print(f\"KullanÄ±lan tekil deÄŸer sayÄ±sÄ±: {len(singular_values)}\")\n",
        "print(f\"Ä°lk 5 tekil deÄŸer: {singular_values[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“ˆ Tekil DeÄŸerler GÃ¶rselleÅŸtirmesi\n",
        "\n",
        "**Bu grafik ne gÃ¶steriyor?**\n",
        "- **X Ekseni**: BileÅŸen numarasÄ± (1, 2, 3, ...)\n",
        "- **Y Ekseni**: Tekil deÄŸer (bileÅŸenin Ã¶nemi)\n",
        "- **YÃ¼ksek deÄŸerler**: Daha Ã¶nemli, daha fazla bilgi taÅŸÄ±yan bileÅŸenler\n",
        "- **DÃ¼ÅŸÃ¼k deÄŸerler**: Daha az Ã¶nemli, gÃ¼rÃ¼ltÃ¼ iÃ§eren bileÅŸenler\n",
        "- **Elbow Point**: Optimal bileÅŸen sayÄ±sÄ±nÄ± belirler (eÄŸrinin dÃ¼ÅŸmeye baÅŸladÄ±ÄŸÄ± nokta)\n",
        "\n",
        "**KÃ¼mÃ¼latif Varyans GrafiÄŸi**:\n",
        "- Ä°lk N bileÅŸenin toplam aÃ§Ä±kladÄ±ÄŸÄ± varyans\n",
        "- %95 eÅŸiÄŸi: Verinin %95'ini korumak iÃ§in gerekli bileÅŸen sayÄ±sÄ±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tekil deÄŸerler gÃ¶rselleÅŸtirme\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Tekil deÄŸerler\n",
        "ax1.plot(range(1, len(singular_values) + 1), singular_values, 'o-', linewidth=2, markersize=6)\n",
        "ax1.set_xlabel('BileÅŸen', fontsize=12)\n",
        "ax1.set_ylabel('Tekil DeÄŸer', fontsize=12)\n",
        "ax1.set_title('Tekil DeÄŸerler (Singular Values)', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# KÃ¼mÃ¼latif varyans\n",
        "cumulative_variance = np.cumsum(singular_values**2) / np.sum(singular_values**2)\n",
        "ax2.plot(range(1, len(singular_values) + 1), cumulative_variance, 'o-', linewidth=2, markersize=6)\n",
        "ax2.axhline(y=0.95, color='r', linestyle='--', label='95% EÅŸiÄŸi')\n",
        "ax2.set_xlabel('BileÅŸen SayÄ±sÄ±', fontsize=12)\n",
        "ax2.set_ylabel('KÃ¼mÃ¼latif Varyans OranÄ±', fontsize=12)\n",
        "ax2.set_title('KÃ¼mÃ¼latif Varyans', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ¯ Ã–neriler ve Rating Matrisi\n",
        "\n",
        "**Ã–neri Sistemi Ã‡alÄ±ÅŸma Prensibi**:\n",
        "1. Model, kullanÄ±cÄ±nÄ±n geÃ§miÅŸ rating'lerini analiz eder\n",
        "2. Latent faktÃ¶rler kullanarak kullanÄ±cÄ± tercihlerini Ã¶ÄŸrenir\n",
        "3. Benzer kullanÄ±cÄ±larÄ±n beÄŸendiÄŸi Ã¼rÃ¼nleri bulur\n",
        "4. KullanÄ±cÄ±nÄ±n henÃ¼z gÃ¶rmediÄŸi Ã¼rÃ¼nler iÃ§in rating tahmin eder\n",
        "5. En yÃ¼ksek tahmin edilen rating'lere sahip Ã¼rÃ¼nleri Ã¶nerir\n",
        "\n",
        "**Rating Matrisi GÃ¶rselleÅŸtirmesi**:\n",
        "- **SatÄ±rlar**: KullanÄ±cÄ±lar\n",
        "- **SÃ¼tunlar**: ÃœrÃ¼nler\n",
        "- **Renkler**: Rating deÄŸerleri (koyu = dÃ¼ÅŸÃ¼k, aÃ§Ä±k = yÃ¼ksek)\n",
        "- **Beyaz alanlar**: Eksik rating'ler (kullanÄ±cÄ± henÃ¼z deÄŸerlendirmemiÅŸ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–neriler Ã¼ret\n",
        "user_idx = 0\n",
        "predictions = svd_model.predict_all()[user_idx]\n",
        "rated_items = ~np.isnan(rating_matrix[user_idx])\n",
        "predictions[rated_items] = -np.inf\n",
        "\n",
        "top_items = np.argsort(predictions)[::-1][:10]\n",
        "top_ratings = predictions[top_items]\n",
        "\n",
        "# Ã–neri gÃ¶rselleÅŸtirme\n",
        "fig = plot_recommendations(user_idx, (top_items, top_ratings))\n",
        "plt.show()\n",
        "\n",
        "# Rating matrisi gÃ¶rselleÅŸtirme\n",
        "fig2 = plot_ratings_matrix(rating_matrix)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SVD - GÃ¼rÃ¼ltÃ¼ Temizleme\n",
        "\n",
        "### ğŸ”‡ SVD ile GÃ¼rÃ¼ltÃ¼ Temizleme NasÄ±l Ã‡alÄ±ÅŸÄ±r?\n",
        "\n",
        "**Prensip**: SVD, veriyi Ã¶nemli bileÅŸenlere ve gÃ¼rÃ¼ltÃ¼ye ayÄ±rÄ±r.\n",
        "\n",
        "**AdÄ±mlar**:\n",
        "1. **SVD Uygulama**: Veri matrisini tekil deÄŸerlerine ayÄ±rÄ±r\n",
        "2. **BileÅŸen SeÃ§imi**: Sadece Ã¶nemli bileÅŸenleri tutar (yÃ¼ksek tekil deÄŸerler)\n",
        "3. **GÃ¼rÃ¼ltÃ¼ Filtreleme**: DÃ¼ÅŸÃ¼k tekil deÄŸerli bileÅŸenleri atar (gÃ¼rÃ¼ltÃ¼)\n",
        "4. **Yeniden OluÅŸturma**: SeÃ§ilen bileÅŸenlerle temiz veriyi yeniden oluÅŸturur\n",
        "\n",
        "### ğŸ“Š Varyans EÅŸiÄŸi\n",
        "\n",
        "- **0.95 (95%)**: Verinin %95'ini korur, %5 gÃ¼rÃ¼ltÃ¼yÃ¼ temizler\n",
        "- **0.90 (90%)**: Daha agresif temizleme, daha fazla gÃ¼rÃ¼ltÃ¼ kaldÄ±rÄ±r\n",
        "- **0.99 (99%)**: Ã‡ok az temizleme, neredeyse tÃ¼m veriyi korur\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–rnek veri oluÅŸtur\n",
        "X, _ = generate_sample_data(n_samples=200, n_features=100, n_clusters=5)\n",
        "X_noisy = generate_noisy_data(X, noise_level=0.2)\n",
        "\n",
        "# SVD ile gÃ¼rÃ¼ltÃ¼ temizleme\n",
        "noise_reducer = SVDNoiseReducer(n_components=None, threshold=0.95)\n",
        "noise_reducer.fit(X_noisy)\n",
        "X_denoised = noise_reducer.denoise(X_noisy)\n",
        "\n",
        "# Metrikler\n",
        "mse_original = np.mean((X - X_noisy)**2)\n",
        "mse_denoised = np.mean((X - X_denoised)**2)\n",
        "improvement = ((mse_original - mse_denoised) / mse_original * 100)\n",
        "noise_reduction_ratio = noise_reducer.get_noise_reduction_ratio()\n",
        "\n",
        "print(f\"GÃ¼rÃ¼ltÃ¼ MSE: {mse_original:.6f}\")\n",
        "print(f\"TemizlenmiÅŸ MSE: {mse_denoised:.6f}\")\n",
        "print(f\"Ä°yileÅŸtirme: {improvement:.2f}%\")\n",
        "print(f\"Varyans korunma oranÄ±: {noise_reduction_ratio:.2%}\")\n",
        "print(f\"KullanÄ±lan bileÅŸen sayÄ±sÄ±: {noise_reducer.n_components}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GÃ¼rÃ¼ltÃ¼ temizleme gÃ¶rselleÅŸtirme\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Orijinal\n",
        "im1 = axes[0].imshow(X[:50, :50], cmap='viridis', aspect='auto')\n",
        "axes[0].set_title('Orijinal Veri', fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# GÃ¼rÃ¼ltÃ¼lÃ¼\n",
        "im2 = axes[1].imshow(X_noisy[:50, :50], cmap='viridis', aspect='auto')\n",
        "axes[1].set_title('GÃ¼rÃ¼ltÃ¼lÃ¼ Veri', fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im2, ax=axes[1])\n",
        "\n",
        "# TemizlenmiÅŸ\n",
        "im3 = axes[2].imshow(X_denoised[:50, :50], cmap='viridis', aspect='auto')\n",
        "axes[2].set_title('TemizlenmiÅŸ Veri', fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im3, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Varyans analizi\n",
        "component_counts, variance_ratios = noise_reducer.get_optimal_components(X_noisy)\n",
        "\n",
        "fig2, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(component_counts, variance_ratios, 'o-', linewidth=2, markersize=6)\n",
        "ax.axhline(y=0.95, color='r', linestyle='--', label='95% EÅŸiÄŸi')\n",
        "ax.axvline(x=noise_reducer.n_components, color='g', \n",
        "          linestyle='--', label=f'SeÃ§ilen ({noise_reducer.n_components})')\n",
        "ax.set_xlabel('BileÅŸen SayÄ±sÄ±', fontsize=12)\n",
        "ax.set_ylabel('KÃ¼mÃ¼latif Varyans OranÄ±', fontsize=12)\n",
        "ax.set_title('Varyans Korunma Analizi', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. PCA - Veri GÃ¶rselleÅŸtirme\n",
        "\n",
        "### ğŸ“ˆ PCA (Principal Component Analysis) Nedir?\n",
        "\n",
        "**PCA**, yÃ¼ksek boyutlu veriyi daha dÃ¼ÅŸÃ¼k boyutlu bir uzaya izdÃ¼ÅŸÃ¼ren bir boyut azaltma tekniÄŸidir.\n",
        "\n",
        "### ğŸ”§ NasÄ±l Ã‡alÄ±ÅŸÄ±r?\n",
        "\n",
        "1. **Kovaryans Matrisi**: Veri Ã¶zellikleri arasÄ±ndaki iliÅŸkileri hesaplar\n",
        "2. **Ã–zvektÃ¶rler**: Verinin ana yÃ¶nlerini (principal components) bulur\n",
        "3. **Ã–zdeÄŸerler**: Her bileÅŸenin ne kadar varyans aÃ§Ä±kladÄ±ÄŸÄ±nÄ± gÃ¶sterir\n",
        "4. **Ä°zdÃ¼ÅŸÃ¼m**: Veriyi yeni dÃ¼ÅŸÃ¼k boyutlu uzaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r\n",
        "\n",
        "### ğŸ¯ KullanÄ±m AlanlarÄ±\n",
        "\n",
        "- **Veri GÃ¶rselleÅŸtirme**: YÃ¼ksek boyutlu veriyi 2D/3D'de gÃ¶rselleÅŸtirme\n",
        "- **Ã–zellik SeÃ§imi**: En Ã¶nemli Ã¶zellikleri belirleme\n",
        "- **Boyut Azaltma**: GÃ¼rÃ¼ltÃ¼yÃ¼ azaltma ve hesaplama hÄ±zÄ±nÄ± artÄ±rma\n",
        "- **Ã–n Ä°ÅŸleme**: Makine Ã¶ÄŸrenmesi modelleri iÃ§in veri hazÄ±rlama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–rnek veri oluÅŸtur\n",
        "X, y = generate_sample_data(n_samples=500, n_features=50, n_clusters=5)\n",
        "\n",
        "# PCA uygula\n",
        "pca = PCAAnalyzer(n_components=None)\n",
        "X_transformed = pca.fit_transform(X)\n",
        "\n",
        "# Analiz\n",
        "n_95 = pca.get_optimal_components(X, variance_threshold=0.95)\n",
        "variance_first_5 = np.sum(pca.explained_variance_ratio_[:5])\n",
        "\n",
        "print(f\"Toplam bileÅŸen sayÄ±sÄ±: {len(pca.explained_variance_ratio_)}\")\n",
        "print(f\"%95 varyans iÃ§in gerekli bileÅŸen sayÄ±sÄ±: {n_95}\")\n",
        "print(f\"Ä°lk 5 bileÅŸenin aÃ§Ä±kladÄ±ÄŸÄ± varyans: {variance_first_5:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AÃ§Ä±klanan varyans grafiÄŸi\n",
        "fig = pca.plot_explained_variance(n_components=20)\n",
        "plt.show()\n",
        "\n",
        "# 2D ve 3D izdÃ¼ÅŸÃ¼mler\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# 2D\n",
        "X_2d = X_transformed[:, :2]\n",
        "scatter1 = ax1.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap='viridis', alpha=0.6, s=50)\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} varyans)', fontsize=12)\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} varyans)', fontsize=12)\n",
        "ax1.set_title('PCA 2D Ä°zdÃ¼ÅŸÃ¼mÃ¼', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=ax1)\n",
        "\n",
        "# 3D\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "X_3d = X_transformed[:, :3]\n",
        "scatter2 = ax2.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], \n",
        "                      c=y, cmap='viridis', alpha=0.6, s=50)\n",
        "ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=10)\n",
        "ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=10)\n",
        "ax2.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})', fontsize=10)\n",
        "ax2.set_title('PCA 3D Ä°zdÃ¼ÅŸÃ¼mÃ¼', fontsize=14, fontweight='bold')\n",
        "plt.colorbar(scatter2, ax=ax2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. NMF - GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme\n",
        "\n",
        "### ğŸ–¼ï¸ NMF (Non-negative Matrix Factorization) Nedir?\n",
        "\n",
        "**NMF**, matrisleri sadece **pozitif deÄŸerlerle** faktÃ¶rize eden bir yÃ¶ntemdir.\n",
        "\n",
        "### ğŸ¨ GÃ¶rÃ¼ntÃ¼ Ä°ÅŸlemede KullanÄ±mÄ±\n",
        "\n",
        "1. **Basis Images (Temel GÃ¶rÃ¼ntÃ¼ler)**: GÃ¶rÃ¼ntÃ¼lerin temel yapÄ± taÅŸlarÄ±nÄ± bulur\n",
        "2. **KatsayÄ± Matrisi**: Her gÃ¶rÃ¼ntÃ¼nÃ¼n bu temel yapÄ± taÅŸlarÄ±nÄ± nasÄ±l kullandÄ±ÄŸÄ±nÄ± gÃ¶sterir\n",
        "3. **Yeniden OluÅŸturma**: Temel gÃ¶rÃ¼ntÃ¼ler ve katsayÄ±larla orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ yeniden oluÅŸturur\n",
        "\n",
        "### âœ… AvantajlarÄ±\n",
        "\n",
        "- **Pozitif DeÄŸerler**: GÃ¶rÃ¼ntÃ¼ piksel deÄŸerleri doÄŸal olarak pozitiftir\n",
        "- **Yorumlanabilirlik**: Temel gÃ¶rÃ¼ntÃ¼ler anlamlÄ± pattern'ler iÃ§erir\n",
        "- **SÄ±kÄ±ÅŸtÄ±rma**: Az sayÄ±da temel gÃ¶rÃ¼ntÃ¼ ile Ã§ok gÃ¶rÃ¼ntÃ¼yÃ¼ temsil edebilir\n",
        "- **GÃ¼rÃ¼ltÃ¼ Azaltma**: DÃ¼ÅŸÃ¼k rank yaklaÅŸÄ±mÄ± gÃ¼rÃ¼ltÃ¼yÃ¼ filtreler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GÃ¶rÃ¼ntÃ¼ verisi yÃ¼kle\n",
        "images_flat, image_shape = load_sample_images(n_images=100)\n",
        "\n",
        "# NMF modeli\n",
        "nmf_image = NMFImageProcessor(n_components=20)\n",
        "nmf_image.fit(images_flat)\n",
        "\n",
        "# Yeniden oluÅŸtur\n",
        "reconstructed = nmf_image.reconstruct()\n",
        "basis_images = nmf_image.get_basis_images(image_shape)\n",
        "compression_ratio = nmf_image.get_compression_ratio(image_shape)\n",
        "\n",
        "# Metrikler\n",
        "mse = np.mean((images_flat - reconstructed)**2)\n",
        "\n",
        "print(f\"SÄ±kÄ±ÅŸtÄ±rma oranÄ±: {compression_ratio:.2f}x\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"Basis gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±: {len(basis_images)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GÃ¶rÃ¼ntÃ¼ gÃ¶rselleÅŸtirme\n",
        "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
        "\n",
        "for i in range(5):\n",
        "    # Orijinal\n",
        "    axes[0, i].imshow(images_flat[i].reshape(image_shape), cmap='gray')\n",
        "    axes[0, i].set_title(f'Orijinal {i+1}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Yeniden oluÅŸturulmuÅŸ\n",
        "    axes[1, i].imshow(reconstructed[i].reshape(image_shape), cmap='gray')\n",
        "    axes[1, i].set_title(f'Yeniden OluÅŸturulmuÅŸ {i+1}')\n",
        "    axes[1, i].axis('off')\n",
        "    \n",
        "    # Fark\n",
        "    diff = np.abs(images_flat[i].reshape(image_shape) - \n",
        "                 reconstructed[i].reshape(image_shape))\n",
        "    axes[2, i].imshow(diff, cmap='hot')\n",
        "    axes[2, i].set_title(f'Fark {i+1}')\n",
        "    axes[2, i].axis('off')\n",
        "\n",
        "plt.suptitle('Orijinal vs Yeniden OluÅŸturulmuÅŸ GÃ¶rÃ¼ntÃ¼ler', \n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Basis gÃ¶rÃ¼ntÃ¼leri\n",
        "basis_flat = basis_images.reshape(len(basis_images), -1)\n",
        "fig2 = plot_image_grid(basis_flat, image_shape, n_cols=5, figsize=(15, 8))\n",
        "plt.suptitle('Temel GÃ¶rÃ¼ntÃ¼ler (Basis Images)', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. NMF - Topic Modeling\n",
        "\n",
        "### ğŸ“ Topic Modeling Nedir?\n",
        "\n",
        "**Topic Modeling**, metin dokÃ¼manlarÄ±nda gizli konularÄ± (topic) keÅŸfetme tekniÄŸidir.\n",
        "\n",
        "### ğŸ”§ NMF ile Topic Modeling\n",
        "\n",
        "1. **TF-IDF VektÃ¶rizasyon**: Metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r\n",
        "2. **NMF FaktÃ¶rizasyon**: DokÃ¼man-kelime matrisini faktÃ¶rize eder\n",
        "3. **Topic Ã‡Ä±karÄ±mÄ±**: Her topic iÃ§in Ã¶nemli kelimeleri bulur\n",
        "4. **DokÃ¼man-Topic DaÄŸÄ±lÄ±mÄ±**: Her dokÃ¼manÄ±n hangi topic'lere ait olduÄŸunu gÃ¶sterir\n",
        "\n",
        "### ğŸ¯ KullanÄ±m AlanlarÄ±\n",
        "\n",
        "- Haber kategorilendirme\n",
        "- MÃ¼ÅŸteri yorumlarÄ± analizi\n",
        "- AraÅŸtÄ±rma makaleleri sÄ±nÄ±flandÄ±rma\n",
        "- Sosyal medya iÃ§erik analizi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metin korpusu oluÅŸtur\n",
        "documents = generate_text_corpus(n_documents=200)\n",
        "\n",
        "# NMF modeli\n",
        "nmf_model = NMFTopicModeler(n_topics=5, max_iter=200)\n",
        "nmf_model.fit(documents, max_features=500, min_df=2, max_df=0.95)\n",
        "\n",
        "# Topic'ler\n",
        "topics = nmf_model.get_topics(n_words=10)\n",
        "coherence = nmf_model.get_topic_coherence()\n",
        "\n",
        "print(f\"Topic tutarlÄ±lÄ±ÄŸÄ±: {coherence:.4f}\\n\")\n",
        "\n",
        "# Topic'leri gÃ¶ster\n",
        "for topic_name, words_scores in topics.items():\n",
        "    print(f\"{topic_name}:\")\n",
        "    for word, score in words_scores[:5]:\n",
        "        print(f\"  - {word}: {score:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topic gÃ¶rselleÅŸtirme\n",
        "fig = plot_topic_words(topics, n_words=10, figsize=(18, 6))\n",
        "plt.show()\n",
        "\n",
        "# DokÃ¼man-topic daÄŸÄ±lÄ±mÄ±\n",
        "doc_topics = nmf_model.get_document_topics()\n",
        "\n",
        "fig2, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.heatmap(doc_topics[:50].T, cmap='YlOrRd', ax=ax, \n",
        "           yticklabels=[f'Topic {i+1}' for i in range(nmf_model.n_topics)],\n",
        "           xticklabels=[f'Doc {i+1}' for i in range(50)])\n",
        "ax.set_xlabel('DokÃ¼manlar', fontsize=12)\n",
        "ax.set_ylabel('Topic\\'ler', fontsize=12)\n",
        "ax.set_title('DokÃ¼man-Topic DaÄŸÄ±lÄ±mÄ± (Ä°lk 50 DokÃ¼man)', \n",
        "            fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ALS - Ã–neri Sistemi\n",
        "\n",
        "### âš¡ ALS (Alternating Least Squares) Nedir?\n",
        "\n",
        "**ALS**, bÃ¼yÃ¼k Ã¶lÃ§ekli Ã¶neri sistemleri iÃ§in optimize edilmiÅŸ bir matris faktÃ¶rizasyon yÃ¶ntemidir.\n",
        "\n",
        "### ğŸ”§ NasÄ±l Ã‡alÄ±ÅŸÄ±r?\n",
        "\n",
        "1. **Alternatif Optimizasyon**: KullanÄ±cÄ± ve Ã¼rÃ¼n faktÃ¶rlerini sÄ±rayla optimize eder\n",
        "2. **Paralel Ä°ÅŸleme**: Her kullanÄ±cÄ±/Ã¼rÃ¼n baÄŸÄ±msÄ±z iÅŸlenebilir (Spark uyumlu)\n",
        "3. **Regularizasyon**: AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nler\n",
        "4. **Iteratif GÃ¼ncelleme**: Her iterasyonda faktÃ¶rleri iyileÅŸtirir\n",
        "\n",
        "### ğŸ†š SVD'den FarklarÄ±\n",
        "\n",
        "- **Paralel Ã‡alÄ±ÅŸma**: BÃ¼yÃ¼k veri setlerinde daha hÄ±zlÄ±\n",
        "- **Eksik Veri**: Sparse matrislerde daha iyi performans\n",
        "- **Ã–lÃ§eklenebilirlik**: Milyonlarca kullanÄ±cÄ±/Ã¼rÃ¼n ile Ã§alÄ±ÅŸabilir\n",
        "- **Regularizasyon**: Daha iyi genelleme\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–rnek rating matrisi\n",
        "rating_matrix = generate_rating_matrix(n_users=100, n_items=50, sparsity=0.7)\n",
        "\n",
        "# Train-test split\n",
        "np.random.seed(42)\n",
        "mask = ~np.isnan(rating_matrix)\n",
        "test_indices = np.random.choice(np.where(mask)[0], \n",
        "                               size=int(0.2 * np.sum(mask)), \n",
        "                               replace=False)\n",
        "test_mask = np.zeros_like(mask, dtype=bool)\n",
        "test_mask.flat[test_indices] = True\n",
        "\n",
        "train_matrix = rating_matrix.copy()\n",
        "train_matrix[test_mask] = np.nan\n",
        "\n",
        "test_matrix = np.full_like(rating_matrix, np.nan)\n",
        "test_matrix[test_mask] = rating_matrix[test_mask]\n",
        "\n",
        "# ALS modeli\n",
        "print(\"ALS modeli eÄŸitiliyor...\")\n",
        "als_model = ALSRecommender(n_factors=20, regularization=0.1, iterations=15)\n",
        "als_model.fit(train_matrix, implicit=False)\n",
        "\n",
        "# DeÄŸerlendirme\n",
        "rmse = als_model.evaluate(test_matrix)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–neriler\n",
        "user_idx = 0\n",
        "recommendations = als_model.recommend(user_idx, n_recommendations=10, \n",
        "                                     exclude_rated=True, \n",
        "                                     rating_matrix=rating_matrix)\n",
        "\n",
        "print(f\"KullanÄ±cÄ± {user_idx+1} iÃ§in Ã¶neriler:\")\n",
        "for i, (item, rating) in enumerate(zip(recommendations[0][:5], recommendations[1][:5]), 1):\n",
        "    print(f\"  {i}. ÃœrÃ¼n {item+1}: {rating:.2f}\")\n",
        "\n",
        "# Benzer item'lar\n",
        "item_idx = 0\n",
        "similar_items = als_model.get_similar_items(item_idx, n_similar=10)\n",
        "\n",
        "print(f\"\\nÃœrÃ¼n {item_idx+1} ile benzer Ã¼rÃ¼nler:\")\n",
        "for i, (item, similarity) in enumerate(zip(similar_items[0][:5], similar_items[1][:5]), 1):\n",
        "    print(f\"  {i}. ÃœrÃ¼n {item+1}: Benzerlik = {similarity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±\n",
        "\n",
        "### ğŸ“Š KarÅŸÄ±laÅŸtÄ±rÄ±lan Algoritmalar\n",
        "\n",
        "**SVD (Singular Value Decomposition)**:\n",
        "- âœ… Matematiksel olarak en kesin\n",
        "- âœ… HÄ±zlÄ± eÄŸitim\n",
        "- âŒ BÃ¼yÃ¼k veri setlerinde yavaÅŸ\n",
        "- âŒ Paralel Ã§alÄ±ÅŸmaya uygun deÄŸil\n",
        "\n",
        "**ALS (Alternating Least Squares)**:\n",
        "- âœ… BÃ¼yÃ¼k Ã¶lÃ§ekli veri setlerinde hÄ±zlÄ±\n",
        "- âœ… Paralel Ã§alÄ±ÅŸmaya uygun (Spark)\n",
        "- âœ… Sparse matrislerde iyi\n",
        "- âŒ Daha fazla iterasyon gerekir\n",
        "\n",
        "### ğŸ“ˆ Metrikler\n",
        "\n",
        "**RMSE (Root Mean Square Error)**:\n",
        "- Tahmin hatasÄ±nÄ±n Ã¶lÃ§Ã¼sÃ¼\n",
        "- **DÃ¼ÅŸÃ¼k RMSE = Daha iyi performans**\n",
        "- FormÃ¼l: âˆš(Î£(tahmin - gerÃ§ek)Â² / n)\n",
        "\n",
        "**EÄŸitim SÃ¼resi**:\n",
        "- Modelin eÄŸitilmesi iÃ§in geÃ§en sÃ¼re\n",
        "- BÃ¼yÃ¼k veri setlerinde Ã¶nemli\n",
        "\n",
        "**Not**: Bu sonuÃ§lar veri setine ve parametrelere baÄŸlÄ±dÄ±r. FarklÄ± veri setlerinde sonuÃ§lar deÄŸiÅŸebilir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVD ve ALS karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
        "rating_matrix = generate_rating_matrix(n_users=100, n_items=50, sparsity=0.7)\n",
        "\n",
        "# Train-test split\n",
        "np.random.seed(42)\n",
        "mask = ~np.isnan(rating_matrix)\n",
        "test_indices = np.random.choice(np.where(mask)[0], \n",
        "                               size=int(0.2 * np.sum(mask)), \n",
        "                               replace=False)\n",
        "test_mask = np.zeros_like(mask, dtype=bool)\n",
        "test_mask.flat[test_indices] = True\n",
        "\n",
        "train_matrix = rating_matrix.copy()\n",
        "train_matrix[test_mask] = np.nan\n",
        "\n",
        "test_matrix = np.full_like(rating_matrix, np.nan)\n",
        "test_matrix[test_mask] = rating_matrix[test_mask]\n",
        "\n",
        "# SVD\n",
        "import time\n",
        "start_time = time.time()\n",
        "svd_model = SVDRecommender(n_components=20)\n",
        "svd_model.fit(train_matrix)\n",
        "svd_train_time = time.time() - start_time\n",
        "svd_rmse = svd_model.evaluate(test_matrix)\n",
        "\n",
        "# ALS\n",
        "start_time = time.time()\n",
        "als_model = ALSRecommender(n_factors=20, regularization=0.1, iterations=15)\n",
        "als_model.fit(train_matrix)\n",
        "als_train_time = time.time() - start_time\n",
        "als_rmse = als_model.evaluate(test_matrix)\n",
        "\n",
        "# SonuÃ§lar\n",
        "results_df = pd.DataFrame({\n",
        "    'Algoritma': ['SVD', 'ALS'],\n",
        "    'RMSE': [svd_rmse, als_rmse],\n",
        "    'EÄŸitim SÃ¼resi (s)': [svd_train_time, als_train_time]\n",
        "})\n",
        "\n",
        "print(\"Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±:\")\n",
        "display(results_df)\n",
        "\n",
        "# GÃ¶rselleÅŸtirme\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "ax1.bar(results_df['Algoritma'], results_df['RMSE'], alpha=0.7, color=['#1f77b4', '#ff7f0e'])\n",
        "ax1.set_ylabel('RMSE', fontsize=12)\n",
        "ax1.set_title('RMSE KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "ax2.bar(results_df['Algoritma'], results_df['EÄŸitim SÃ¼resi (s)'], \n",
        "       alpha=0.7, color=['#1f77b4', '#ff7f0e'])\n",
        "ax2.set_ylabel('EÄŸitim SÃ¼resi (saniye)', fontsize=12)\n",
        "ax2.set_title('EÄŸitim SÃ¼resi KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
